
---
jupyter: ds-flood-gfm
---
## Simple STAC based approach to recent composites

```{python}
import pystac_client
import stackstac
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap, BoundaryNorm
import numpy as np

import numpy as np

# Configure matplotlib for better display
%matplotlib inline
plt.rcParams['figure.dpi'] = 100

```


## Spatio-temporal Ranges

Define spatial-temporal range. For this example we just define aoi lon/lat as a point
but later we'd probably want larger bbox's

We should be able to define any start range and cumulatively fill with most recent values.

Here we cover Oct-December 2024 and a point in Somalia
```{python}
lon, lat = 12.299,9.4727
start_date = "2023-10-01"
end_date = "2023-12-31"
```


## STAC - connect & query
```{python}

stac_api = "https://stac.eodc.eu/api/v1"
client = pystac_client.Client.open(stac_api)


# Step 2: Search for GFM items
datetime_range = f"{start_date}/{end_date}"
search = client.search(
    collections=["GFM"],
    intersects=dict(type="Point", coordinates=[lon, lat]),
    # bbox=aoi,
    datetime=datetime_range
    # limit=20  # Maximum number of STAC items/scenes to return
    # Each item = one satellite image/scene at a specific time
    # Without limit, you might get hundreds of results
    # limit=20 means "give me up to 20 scenes that match my criteria"
)

item_collection = search.get_all_items()
stack = stackstac.stack(item_collection,epsg= 4326)


```


## Processing

Create ImageCollection of latest composites up to the date of each image
```{python}
stack
ic_latest = stack.sel(band="ensemble_flood_extent").ffill(dim= "time")

```


## View Results

Select Snapshots to visually inspect and make sure it's working
```{python}
# Get 3 Image snap-shots from STAC for visualization of concept
img_tstart = ic_latest.isel(time =0)
img_tend = ic_latest.isel(time = -1 )
img_t2 = ic_latest.isel(time =2)
img_t45= ic_latest.isel(time =45)

```

plots to visualize snapshots together

```{python plots}

# Create 3 subplots for the three time points
fig, axes = plt.subplots(2, 2, figsize=(6, 6))
ax1, ax2, ax3, ax4 = axes.flatten()

# Define colors for flood data
# Simple approach: mask nodata (255) and use binary colormap for 0/1
colors = ["white", "blue"]  # 0=not flooded (white), 1=flooded (blue)
flood_cmap = ListedColormap(colors)


# Plot start image (ensemble_flood_extent band)
img_tstart.plot(ax=ax1, cmap=flood_cmap, vmin=0, vmax=1, add_colorbar=True)
ax1.set_title("Start (Time 0)")
ax1.set_xlabel("Longitude")
ax1.set_ylabel("Latitude")

# Plot midway image
img_t2.plot(ax=ax2, cmap=flood_cmap, vmin=0, vmax=1, add_colorbar=True)
ax2.set_title("Day 2 (Time 2)")
ax2.set_xlabel("Longitude")
ax2.set_ylabel("Latitude")

# Plot latest image
img_t45.plot(ax=ax3, cmap=flood_cmap, vmin=0, vmax=1, add_colorbar=True)
ax3.set_title("Midway (Day-45)")
ax3.set_xlabel("Longitude")
ax3.set_ylabel("Latitude")

plt.tight_layout()
plt.show()
fig
```



## Check advisory bands

We want to see if we can query huge areas for flood advisory. Return only tiles with anomaly.

```{python}
import geopandas as gpd 
url = "https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip"
world = gpd.read_file(url)

rename_mapper = {"POP_EST": "pop_est",
                 "CONTINENT": "continent",
                 "ADMIN": "name",
                 "ADM0_A3": "iso_a3",
                 "GDP_MD": "gdp_md_est"}
world.rename(rename_mapper, axis="columns", inplace=True)
gdf_africa = world[world.continent == "Africa"]
gdf_africa_bound = gdf_africa.total_bounds
gdf_world_bound = world.total_bounds
```

```{python}
search = client.search(
    collections=["GFM"],
    # intersects=dict(type="Point", coordinates=[lon, lat]),
    bbox=gdf_africa_bound,  # Huge geographic extent
    datetime="2025-09-15/2025-09-21",
    query={"anomaly_detected": {"eq": True}},  # Only scenes with advisories
)


item_collection = search.item_collection()
stack = stackstac.stack(item_collection, epsg=4326)
```


search world
```{python}
gdf_world_bound
search = client.search(
    collections=["GFM"],
    # intersects=dict(type="Point", coordinates=[lon, lat]),
    bbox=np.array([-180, -90, 180, 90]),  # Huge geographic extent
    datetime="2025-09-21/2025-09-21",
    query={"anomaly_detected": {"eq": True}},  # Only scenes with advisories
)


item_collection = search.get_all_items()
stack = stackstac.stack(item_collection, epsg=4326)
```


```{python}
## Claude - code here:

# Extract advisory geometries and metadata efficiently
advisory_tiles = []
for item in item_collection:
    advisory_tiles.append(
        {
            "geometry": shape(item.geometry),
            "datetime": item.datetime,
            "anomaly_detected": item.properties.get("anomaly_detected", False),
            "flooded_pixels": item.properties.get("flooded_pixels", 0),
            "tile_id": item.properties.get("Equi7Tile"),
            "id": item.id,
        }
    )

# Convert to GeoDataFrame
advisory_gdf = gpd.GeoDataFrame(advisory_tiles)
advisory_gdf["date"] = advisory_gdf["datetime"].dt.date
max_per_day = advisory_gdf.loc[
    advisory_gdf.groupby(["date", "tile_id"])["flooded_pixels"].idxmax()
]


# Optional: Also add a general filter for degenerate geometries
def is_reasonable_geometry(geom):
    bounds = geom.bounds
    width = bounds[2] - bounds[0]
    height = bounds[3] - bounds[1]
    return width < 50 and height < 50 and width > 0.01 and height > 0.01


max_per_day = max_per_day[max_per_day.geometry.apply(is_reasonable_geometry)]

print(f"Total advisory items: {len(advisory_gdf)}")
print(f"After filtering: {len(max_per_day)}")


# Filter for the last 3 days and create individual plots
from datetime import datetime, timedelta
import pandas as pd

# Get the last 3 days (Sep 21, 20, 19)
target_dates = ["2025-09-21", "2025-09-20", "2025-09-19"]

# Create subplots for the 3 days
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

# Calculate global min/max for consistent color scale
all_data = max_per_day[
    max_per_day["datetime"].dt.date.isin(
        [pd.to_datetime(date).date() for date in target_dates]
    )
]

if len(all_data) > 0:
    # Use log scale for color mapping
    from matplotlib.colors import LogNorm
    import matplotlib.ticker as ticker

    # Get min/max values, ensuring we don't have zeros for log scale
    min_val = max(all_data["flooded_pixels"].min(), 1)  # Avoid log(0)
    max_val = all_data["flooded_pixels"].max()

    # Create log normalizer
    log_norm = LogNorm(vmin=min_val, vmax=max_val)
else:
    log_norm = None
    min_val, max_val = 0, 1

for i, date_str in enumerate(target_dates):
    # Filter data for specific date
    date_data = max_per_day[
        max_per_day["datetime"].dt.date == pd.to_datetime(date_str).date()
    ]

    # Plot on corresponding subplot
    ax = axes[i]

    # Plot Africa first as background
    gdf_africa.plot(ax=ax, color="lightgray", edgecolor="gray", alpha=0.5)

    if len(date_data) > 0:
        # Plot with log-scaled colors but original values in legend
        im = date_data.plot(
            ax=ax,
            column="flooded_pixels",
            cmap="Reds",
            edgecolor="darkred",
            alpha=0.8,
            linewidth=0.5,
            norm=log_norm,
            legend=True,
            legend_kwds={
                "label": "Flooded Pixels",
                "shrink": 0.8,
                "format": ticker.ScalarFormatter(),  # Show actual numbers, not log values
            },
        )
        ax.set_title(f"Advisory Tiles - {date_str}\n({len(date_data)} tiles)")
    else:
        ax.set_title(f"Advisory Tiles - {date_str}\n(No data)")

    ax.set_xlabel("Longitude")
    ax.set_ylabel("Latitude")
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
fig
```


```{python}

# Create single plot for the one date
fig, ax = plt.subplots(1, 1, figsize=(12, 8))

# Calculate min/max for color scale
all_data = max_per_day

if len(all_data) > 0:
    # Use log scale for color mapping
    from matplotlib.colors import LogNorm
    import matplotlib.ticker as ticker

    # Get min/max values, ensuring we don't have zeros for log scale
    min_val = max(all_data["flooded_pixels"].min(), 1)  # Avoid log(0)
    max_val = all_data["flooded_pixels"].max()

    # Create log normalizer
    log_norm = LogNorm(vmin=min_val, vmax=max_val)
else:
    log_norm = None
    min_val, max_val = 0, 1

# Plot world as background
world.plot(ax=ax, color="lightgray", edgecolor="gray", alpha=0.5)

if len(max_per_day) > 0:
    # Plot with log-scaled colors but original values in legend
    im = max_per_day.plot(
        ax=ax,
        column="flooded_pixels",
        cmap="Reds",
        edgecolor="darkred",
        alpha=0.8,
        linewidth=0.5,
        norm=log_norm,
        legend=True,
        legend_kwds={
            "label": "Flooded Pixels",
            "shrink": 0.8,
            "format": ticker.ScalarFormatter(),  # Show actual numbers, not log values
        },
    )
    ax.set_title(f"Advisory Tiles\n({len(max_per_day)} tiles)")
else:
    ax.set_title("Advisory Tiles\n(No data)")

ax.set_xlabel("Longitude")
ax.set_ylabel("Latitude")
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
fig
```
## View Results

```{python}
ic_advisories = stack.sel(band="ensemble_flood_extent")  # .ffill(dim= "time")

# Get the advisory data for plotting
img_advisory = ic_advisories[[6]]

# Create the plot
fig, ax = plt.subplots(1, 1, figsize=(8, 6))

# Plot the advisory data
img_advisory.plot(ax=ax, cmap=flood_cmap, vmin=0, vmax=1, add_colorbar=True)
ax.set_title("Advisory Flood Extent (Time 0)")
ax.set_xlabel("Longitude")
ax.set_ylabel("Latitude")

plt.tight_layout()
plt.show()
fig


```


Select Snapshots to visually inspect and make sure it's working
```{python}
# Get 3 Image snap-shots from STAC for visualization of concept
img_tstart = ic_latest.isel(time =0)
img_tend = ic_latest.isel(time = -1 )
img_t2 = ic_latest.isel(time =2)
img_t45= ic_latest.isel(time =45)

```


```{python}
ic_advisory_flags = stack.sel(band="advisory_flags")
img_advisory_flag = ic_advisory_flags.isel(time=0)


img_advisory_flag.plot()
plt.show()
```


```{python}

import geopandas as gpd
from shapely.geometry import shape

gdf = gpd.GeoDataFrame(
    [
        {"id": item.id, "datetime": item.datetime, "geometry": shape(item.geometry)}
        for item in item_collection
    ]
)  

```



```{python}
## Claude - code here:

# Analyze duplicate geometries and 
#different datetimes
print(f"Total items: {len(gdf)}")
print(f"Unique geometries: {gdf.geometry.nunique()}")
print(f"Unique dates: {gdf['datetime'].dt.date.nunique()}")

# Group by geometry to find duplicates
geom_groups =gdf.groupby(gdf.geometry.astype(str))
duplicate_geoms =geom_groups.filter(lambda x: len(x) >1)

print(f"\nItems with duplicate 
geometries: {len(duplicate_geoms)}")

  # Look at first duplicate geometry group
if len(duplicate_geoms) > 0:
    first_geom = duplicate_geoms.geometry

try astype(str).iloc[0]:
    same_geom_items =gdf[gdf.geometry.astype(str) ==first_geom]

    print(f"\nExample - same geometry,
different times:")
    for idx, row in
same_geom_items.iterrows():
        print(f"ID: {row['id']}")
        print(f"DateTime: 
{row['datetime']}")
        print(f"DOY: {row['doy']}")
        print("---")

# Check time differences within same 
date
gdf['date'] = gdf['datetime'].dt.date
same_date_groups = gdf.groupby('date')
for date, group in same_date_groups:
    if len(group) > 1:
        time_diff =
group['datetime'].max() -
group['datetime'].min()
        if time_diff.total_seconds() >
0:
            print(f"\nDate {date} has 
{len(group)} items with time range: 
{time_diff}")
            for idx, row in
group.iterrows():
                print(f"  
{row['datetime'].time()} - 
{row['id']}")

```

```{python}
# Extract day of year from datetime
gdf["doy"] = gdf["datetime"].dt.dayofyear
gdf["doy"].unique()
# Plot geometries colored by DOY
fig, ax = plt.subplots(figsize=(12, 8))
gdf.plot(
    column="doy",
    ax=ax,
    linewidth=1,
    alpha=0.7,
    cmap="viridis",
    facecolor="none",
    legend=True,
    legend_kwds={"label": "Day of Year", "shrink": 0.8},
)

ax.set_title("STAC Item Footprints Colored by Day of Year")
ax.set_xlabel("Longitude")
ax.set_ylabel("Latitude")
plt.tight_layout()
plt.show()
fig
```


## Scrap - Ignore below

```{python}
latest_composite = stack.ffill(dim="time").isel(time=-1)
time0
single_band = latest_composite.sel(band="ensemble_flood_extent")

import matplotlib.pyplot as plt
import numpy as np

# Configure matplotlib for better display
%matplotlib inline
plt.rcParams['figure.dpi'] = 100

# Plot just the single_band composite
fig, ax = plt.subplots(1, 1, figsize=(10, 8))
im1 = single_band.plot(ax=ax, cmap="viridis", add_colorbar=True)
ax.set_title("Latest Valid Composite - ensemble_flood_extent")
ax.set_xlabel("Longitude")
ax.set_ylabel("Latitude")
plt.tight_layout()
plt.show()

# Alternative: Force display without plt.show()
fig
```



### TBD

```{python}

# Method 2: Alternative approach using where and reduce operations
# This finds the last valid value by working backwards through time
import xarray as xr

def get_latest_valid(data_array):
    """
    Get the latest valid (non-NaN) value for each pixel across the time dimension
    """
    # Create a mask for valid (non-NaN) values
    valid_mask = ~data_array.isnull()
    
    # Get the index of the last valid value for each pixel
    last_valid_time = valid_mask.cumsum(dim='time').argmax(dim='time')
    
    # Use advanced indexing to get the last valid value
    result = data_array.isel(time=last_valid_time)
    
    # Mask out pixels that had no valid values
    any_valid = valid_mask.any(dim='time')
    result = result.where(any_valid)
    
    return result

# Apply the function to get latest valid composite
latest_composite_v2 = get_latest_valid(stack)

# Display information about the composites
print("Latest composite shape:", latest_composite.shape)
print("Latest composite (v2) shape:", latest_composite_v2.shape)

```

```{python}
# First, let's examine the structure of our composite
print("Latest composite dimensions:", latest_composite.dims)
print("Latest composite coordinates:", list(latest_composite.coords))
print(
    "Latest composite data variables:",
    (
        list(latest_composite.data_vars)
        if hasattr(latest_composite, "data_vars")
        else "Not a Dataset"
    ),
)

# Check if it has a 'band' dimension and what bands are available
if "band" in latest_composite.dims:
    print("Available bands:", latest_composite.band.values)
    print("Number of bands:", len(latest_composite.band.values))

    # Select the ensemble_flood_extent band specifically
    if "ensemble_flood_extent" in latest_composite.band.values:
        
        print(f"Selected band: ensemble_flood_extent")
        print(f"Selected band shape: {single_band.shape}")
    else:
        print("ensemble_flood_extent band not found, using first band as fallback")
        single_band = latest_composite.isel(band=0)
        print(f"Selected band: {latest_composite.band.values[0]}")
        print(f"Selected band shape: {single_band.shape}")
else:
    print("No 'band' dimension found")
    single_band = latest_composite

```

```{python}
import matplotlib.pyplot as plt
import numpy as np

# Plot the latest composite using a single band
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Plot method 1 composite (ensemble_flood_extent band)
if "band" in latest_composite.dims:
    if "ensemble_flood_extent" in latest_composite.band.values:
        im1 = latest_composite.sel(band="ensemble_flood_extent").plot(
            ax=ax1, cmap="viridis", add_colorbar=True
        )
        ax1.set_title(
            "Latest Valid Composite (Method 1: ffill)\nBand: ensemble_flood_extent"
        )
    else:
        im1 = latest_composite.isel(band=0).plot(
            ax=ax1, cmap="viridis", add_colorbar=True
        )
        band_name = latest_composite.band.values[0]
        ax1.set_title(f"Latest Valid Composite (Method 1: ffill)\nBand: {band_name}")
else:
    im1 = latest_composite.plot(ax=ax1, cmap="viridis", add_colorbar=True)
    ax1.set_title("Latest Valid Composite (Method 1: ffill)")

ax1.set_xlabel("Longitude")
ax1.set_ylabel("Latitude")

# Plot method 2 composite for comparison (also handle bands)
if "band" in latest_composite_v2.dims:
    if "ensemble_flood_extent" in latest_composite_v2.band.values:
        im2 = latest_composite_v2.sel(band="ensemble_flood_extent").plot(
            ax=ax2, cmap="viridis", add_colorbar=True
        )
        ax2.set_title(
            "Latest Valid Composite (Method 2: custom)\nBand: ensemble_flood_extent"
        )
    else:
        im2 = latest_composite_v2.isel(band=0).plot(
            ax=ax2, cmap="viridis", add_colorbar=True
        )
        band_name = latest_composite_v2.band.values[0]
        ax2.set_title(f"Latest Valid Composite (Method 2: custom)\nBand: {band_name}")
else:
    im2 = latest_composite_v2.plot(ax=ax2, cmap="viridis", add_colorbar=True)
    ax2.set_title("Latest Valid Composite (Method 2: custom)")

ax2.set_xlabel("Longitude")
ax2.set_ylabel("Latitude")

plt.tight_layout()
plt.show()

# Also create a single larger plot focusing on method 1
fig, ax = plt.subplots(1, 1, figsize=(10, 8))

# Select ensemble_flood_extent band for the detailed plot
if "band" in latest_composite.dims:
    if "ensemble_flood_extent" in latest_composite.band.values:
        plot_data = latest_composite.sel(band="ensemble_flood_extent")
        title = "Latest Valid Flood Composite (Band: ensemble_flood_extent)\n(Most Recent Non-Null Value per Pixel)"
    else:
        plot_data = latest_composite.isel(band=0)
        band_name = latest_composite.band.values[0]
        title = f"Latest Valid Flood Composite (Band: {band_name})\n(Most Recent Non-Null Value per Pixel)"
else:
    plot_data = latest_composite
    title = "Latest Valid Flood Composite\n(Most Recent Non-Null Value per Pixel)"

plot_data.plot(
    ax=ax,
    cmap="RdYlBu_r",
    add_colorbar=True,
    cbar_kwargs={"label": "Flood Values", "shrink": 0.8},
)
ax.set_title(title, fontsize=14, fontweight="bold")
ax.set_xlabel("Longitude", fontsize=12)
ax.set_ylabel("Latitude", fontsize=12)
ax.grid(True, alpha=0.3)

# Add some basic statistics
print(
    f"Composite data range: {plot_data.min().values:.3f} to {plot_data.max().values:.3f}"
)
print(f"Number of valid pixels: {(~plot_data.isnull()).sum().values}")
print(
    f"Percentage of valid pixels: {((~plot_data.isnull()).sum() / plot_data.size * 100).values:.1f}%"
)

plt.tight_layout()
plt.show()

```
